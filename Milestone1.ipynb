{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link: https://patches12306.github.io/patches12306/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garrett Van Beek\n",
    "## Ben Nguyen\n",
    "## Intro to Data Science\n",
    "## Professor Nick Mattei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Tutorial Milestone 1: “Can you Google the stock market?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project we plan to collect data on search traffic from Google and Twitter and see how that data correlates with the performances of certain publicly traded stocks. For example, one question we would like to ask is “how does the search traffic about clean energy sources correlate with the performance of clean energy stocks?”. We would also like to see how the sentiment about certain topics correlates to their stock. For this, we plan to use a python library Twitter Sentiment Analysis or Tweepy. This tool gives us a sentiment rating that we can compare to our stock’s performance. We will most likely analyze our data as line graphs. This way we can see how stock performance, search traffic, and sentiment change over time. Consequently, we hope to find correlations and gain insight on the data.\n",
    "\n",
    "We hope to tackle topics that are a bit more controversial or nuanced than clean energy. Some of the questions that we have thought of asking are: “How does search traffic on sex scandals within companies correlate to the stocks of the companies?” We can also observe the effects of influencers like Donald Trump or Kanye West have on the stock market. We can observe their twitter comments about certain topics and then observe how stocks relating to these topic’s perform. Another angle we can observe is how the general sentiment on topics will correlate to related stocks. For example, we can ask “How does the sentiment about Elon Musk correlate to the stock performance of TESLA?”\n",
    "\n",
    "For our information on stock performance we plan on scraping or downloading data from Yahoo Finance, which contains a barrage of data on publicly traded stocks. Links to the datasets, tools, and websites we plan to use are provided below.\n",
    "\n",
    "https://trends.google.com/trends/?geo=US https://www.tweepy.org/ https://github.com/shaypal5/awesome-twitter-data https://finance.yahoo.com/\n",
    "\n",
    "tutorial project for datascience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Tutorial Milestone 2\n",
    "\n",
    "## Questions\n",
    "Our overall goal is to determine \"Can we google the stock market?\" By this we mean \"can we find correlations between google search trends/twitter activity on certain topics and the performance of stocks related to those topics?\"\n",
    "\n",
    "This is a very general questions so we will answer two specific questions based on our search history. \n",
    "\n",
    "### 1. How does Elon Musk's Twitter activity correlate to the stock performance of Tesla. How do search trends on Elon Musk correlate to the performance of Tesla Stock?\n",
    "Note: we are currently waiting for authorization to use Twitter's Tweepy API. Until then, we will be using google trend data from Google Trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step One: Get the Data\n",
    "We download google search data as CSVs. Our goal is to create a DataFrame where every day is a row, and the columns are:\n",
    "1. Search trends of Elon Musk\n",
    "2. Performance of TESLA Stock\n",
    "3. Performance of PAYPAL Stock\n",
    "\n",
    "Our timeframe for these questions will be 2016-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open_t</th>\n",
       "      <th>High_t</th>\n",
       "      <th>Low_t</th>\n",
       "      <th>Close_t</th>\n",
       "      <th>Adj Close_t</th>\n",
       "      <th>Volume_t</th>\n",
       "      <th>Open_p</th>\n",
       "      <th>High_p</th>\n",
       "      <th>Low_p</th>\n",
       "      <th>Close_p</th>\n",
       "      <th>Adj Close_p</th>\n",
       "      <th>Volume_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>230.720001</td>\n",
       "      <td>231.380005</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>223.410004</td>\n",
       "      <td>223.410004</td>\n",
       "      <td>6827100</td>\n",
       "      <td>35.130001</td>\n",
       "      <td>35.560001</td>\n",
       "      <td>34.279999</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>12287700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>226.360001</td>\n",
       "      <td>226.889999</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>223.429993</td>\n",
       "      <td>223.429993</td>\n",
       "      <td>3186800</td>\n",
       "      <td>34.980000</td>\n",
       "      <td>34.980000</td>\n",
       "      <td>33.860001</td>\n",
       "      <td>34.310001</td>\n",
       "      <td>34.310001</td>\n",
       "      <td>11227700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>220.050003</td>\n",
       "      <td>215.979996</td>\n",
       "      <td>219.039993</td>\n",
       "      <td>219.039993</td>\n",
       "      <td>3779100</td>\n",
       "      <td>33.700001</td>\n",
       "      <td>34.009998</td>\n",
       "      <td>33.209999</td>\n",
       "      <td>33.980000</td>\n",
       "      <td>33.980000</td>\n",
       "      <td>8441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>214.190002</td>\n",
       "      <td>218.440002</td>\n",
       "      <td>213.669998</td>\n",
       "      <td>215.649994</td>\n",
       "      <td>215.649994</td>\n",
       "      <td>3554300</td>\n",
       "      <td>33.150002</td>\n",
       "      <td>34.160999</td>\n",
       "      <td>33.020000</td>\n",
       "      <td>33.130001</td>\n",
       "      <td>33.130001</td>\n",
       "      <td>11041100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>217.860001</td>\n",
       "      <td>220.440002</td>\n",
       "      <td>210.770004</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>3628100</td>\n",
       "      <td>33.459999</td>\n",
       "      <td>33.880001</td>\n",
       "      <td>32.630001</td>\n",
       "      <td>32.689999</td>\n",
       "      <td>32.689999</td>\n",
       "      <td>7848800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>749</td>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>313.500000</td>\n",
       "      <td>314.500000</td>\n",
       "      <td>295.200012</td>\n",
       "      <td>295.390015</td>\n",
       "      <td>295.390015</td>\n",
       "      <td>5559900</td>\n",
       "      <td>77.480003</td>\n",
       "      <td>79.320000</td>\n",
       "      <td>76.699997</td>\n",
       "      <td>77.059998</td>\n",
       "      <td>77.059998</td>\n",
       "      <td>6800500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>326.970001</td>\n",
       "      <td>294.089996</td>\n",
       "      <td>326.089996</td>\n",
       "      <td>326.089996</td>\n",
       "      <td>8163100</td>\n",
       "      <td>77.699997</td>\n",
       "      <td>82.800003</td>\n",
       "      <td>77.650002</td>\n",
       "      <td>82.800003</td>\n",
       "      <td>82.800003</td>\n",
       "      <td>10994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>751</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>319.839996</td>\n",
       "      <td>322.170013</td>\n",
       "      <td>301.500000</td>\n",
       "      <td>316.130005</td>\n",
       "      <td>316.130005</td>\n",
       "      <td>8575100</td>\n",
       "      <td>81.330002</td>\n",
       "      <td>84.360001</td>\n",
       "      <td>80.239998</td>\n",
       "      <td>84.309998</td>\n",
       "      <td>84.309998</td>\n",
       "      <td>7849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>752</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>323.100006</td>\n",
       "      <td>336.239990</td>\n",
       "      <td>318.410004</td>\n",
       "      <td>333.869995</td>\n",
       "      <td>333.869995</td>\n",
       "      <td>9939000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.230003</td>\n",
       "      <td>82.339996</td>\n",
       "      <td>83.260002</td>\n",
       "      <td>83.260002</td>\n",
       "      <td>6850400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>337.790009</td>\n",
       "      <td>339.209991</td>\n",
       "      <td>325.260010</td>\n",
       "      <td>332.799988</td>\n",
       "      <td>332.799988</td>\n",
       "      <td>6302300</td>\n",
       "      <td>84.239998</td>\n",
       "      <td>84.480003</td>\n",
       "      <td>82.550003</td>\n",
       "      <td>84.089996</td>\n",
       "      <td>84.089996</td>\n",
       "      <td>7247700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>754 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      Open_t      High_t       Low_t     Close_t  Adj Close_t  \\\n",
       "0    2016-01-04  230.720001  231.380005  219.000000  223.410004   223.410004   \n",
       "1    2016-01-05  226.360001  226.889999  220.000000  223.429993   223.429993   \n",
       "2    2016-01-06  220.000000  220.050003  215.979996  219.039993   219.039993   \n",
       "3    2016-01-07  214.190002  218.440002  213.669998  215.649994   215.649994   \n",
       "4    2016-01-08  217.860001  220.440002  210.770004  211.000000   211.000000   \n",
       "..          ...         ...         ...         ...         ...          ...   \n",
       "749  2018-12-24  313.500000  314.500000  295.200012  295.390015   295.390015   \n",
       "750  2018-12-26  300.000000  326.970001  294.089996  326.089996   326.089996   \n",
       "751  2018-12-27  319.839996  322.170013  301.500000  316.130005   316.130005   \n",
       "752  2018-12-28  323.100006  336.239990  318.410004  333.869995   333.869995   \n",
       "753  2018-12-31  337.790009  339.209991  325.260010  332.799988   332.799988   \n",
       "\n",
       "     Volume_t     Open_p     High_p      Low_p    Close_p  Adj Close_p  \\\n",
       "0     6827100  35.130001  35.560001  34.279999  34.750000    34.750000   \n",
       "1     3186800  34.980000  34.980000  33.860001  34.310001    34.310001   \n",
       "2     3779100  33.700001  34.009998  33.209999  33.980000    33.980000   \n",
       "3     3554300  33.150002  34.160999  33.020000  33.130001    33.130001   \n",
       "4     3628100  33.459999  33.880001  32.630001  32.689999    32.689999   \n",
       "..        ...        ...        ...        ...        ...          ...   \n",
       "749   5559900  77.480003  79.320000  76.699997  77.059998    77.059998   \n",
       "750   8163100  77.699997  82.800003  77.650002  82.800003    82.800003   \n",
       "751   8575100  81.330002  84.360001  80.239998  84.309998    84.309998   \n",
       "752   9939000  85.000000  85.230003  82.339996  83.260002    83.260002   \n",
       "753   6302300  84.239998  84.480003  82.550003  84.089996    84.089996   \n",
       "\n",
       "     Volume_p  \n",
       "0    12287700  \n",
       "1    11227700  \n",
       "2     8441300  \n",
       "3    11041100  \n",
       "4     7848800  \n",
       "..        ...  \n",
       "749   6800500  \n",
       "750  10994700  \n",
       "751   7849100  \n",
       "752   6850400  \n",
       "753   7247700  \n",
       "\n",
       "[754 rows x 13 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read csv into dataframe\n",
    "tesla_df = pd.read_csv('./data/tesla2016-2018.csv')\n",
    "paypal_df = pd.read_csv('./data/paypal2016-2018.csv')\n",
    "# elon_df = pd.read_csv('./data/elon2016-2018.csv')\n",
    "\n",
    "# tesla_df\n",
    "# paypal_df\n",
    "# elon_df[\"Date\"] = elon_df[\"Week\"]\n",
    "# elon_df\n",
    "\n",
    "# tesla_df[\"Date\"]\n",
    "joined_df = pd.merge(tesla_df, paypal_df, on=\"Date\", how=\"inner\", suffixes=('_t','_p'))\n",
    "# complete_df = pd.merge(joined_df, elon_df, on=\"Date\", how=\"left\")\n",
    "# complete_df[\"Week\"].count()\n",
    "# complete_df\n",
    "joined_df\n",
    "\n",
    "# filter the data so the only columns are date, closing price of tesla and paypal\n",
    "# slim_df = joined_df[[\"Date\", \"Close_t\", \"Close_p\"]]\n",
    "# slim_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
